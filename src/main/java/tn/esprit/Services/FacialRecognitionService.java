package tn.esprit.Services;

import tn.esprit.Models.User;
import org.bytedeco.javacpp.DoublePointer;
import org.bytedeco.javacpp.IntPointer;
import org.bytedeco.javacv.*;
import org.bytedeco.opencv.opencv_core.*;
import org.bytedeco.opencv.opencv_face.FaceRecognizer;
import org.bytedeco.opencv.opencv_face.LBPHFaceRecognizer;
import org.bytedeco.opencv.opencv_objdetect.CascadeClassifier;

import java.io.File;
import java.io.IOException;
import java.io.InputStream;
import java.nio.file.Files;
import java.nio.file.StandardCopyOption;
import java.util.ArrayList;
import java.util.List;

import static org.bytedeco.opencv.global.opencv_core.CV_32SC1;
import static org.bytedeco.opencv.global.opencv_core.addWeighted;
import static org.bytedeco.opencv.global.opencv_imgcodecs.*;
import static org.bytedeco.opencv.global.opencv_imgproc.*;

public class FacialRecognitionService {
    // Utiliser un r√©pertoire utilisateur pour les donn√©es persistantes
    private final String FACE_DATA_DIR = System.getProperty("user.home") + File.separator +
            ".syncylinky" + File.separator + "face_data" + File.separator;
    private CascadeClassifier faceDetector;
    private FaceRecognizer faceRecognizer;
    private UserService userService;

    // Constantes pour am√©liorer la lisibilit√© et la maintenance
    private static final int FACE_IMAGE_SIZE = 200;
    private static final int REGISTER_FACE_COUNT = 8;    // R√©duit pour acc√©l√©rer la d√©mo
    private static final int RECOGNITION_ATTEMPTS = 60;  // Augment√© pour donner plus de temps
    private static final double RECOGNITION_THRESHOLD = 70.0; // Valeur plus permissive pour cam√©ras de faible qualit√©
    private static final double VERIFICATION_THRESHOLD = 80.0; // Valeur plus permissive

    // Param√®tres pour les cam√©ras de basse qualit√©
    private static final double SCALE_FACTOR = 1.05;     // Plus petit pour une d√©tection plus pr√©cise
    private static final int MIN_NEIGHBORS = 2;         // R√©duit pour cam√©ras de basse qualit√©

    // Valeurs pour l'am√©lioration des images
    private static final double BRIGHTNESS_ALPHA = 1.2;  // Facteur d'am√©lioration de la luminosit√©
    private static final double BRIGHTNESS_BETA = 15;    // Valeur d'ajout pour la luminosit√©

    // D√©lais pour rendre les √©tapes plus visibles
    private static final int DETECTION_DELAY = 200;      // ms entre chaque frame
    private static final int CONFIRMATION_DELAY = 2000;  // ms pour afficher les confirmations

    // Taille minimale du visage requise
    private static final int MIN_FACE_SIZE = 80;         // Plus petit pour les cam√©ras basse qualit√©

    public FacialRecognitionService() {
        userService = new UserService();
        initFaceDetector();
        initFaceRecognizer();
    }

    private void initFaceDetector() {
        // Initialiser le d√©tecteur de visage Haar Cascade
        faceDetector = new CascadeClassifier();

        try {
            // Chemin dans les ressources
            String cascadeResourcePath = "/haarcascade_frontalface_default.xml";

            // Extraire le fichier depuis les ressources vers un fichier temporaire
            File tempFile = File.createTempFile("cascade", ".xml");
            tempFile.deleteOnExit();

            try (InputStream is = getClass().getResourceAsStream(cascadeResourcePath)) {
                if (is == null) {
                    System.err.println("Le fichier cascade n'a pas √©t√© trouv√© dans les ressources: " + cascadeResourcePath);
                    return;
                }

                Files.copy(is, tempFile.toPath(), StandardCopyOption.REPLACE_EXISTING);
            }

            // Charger depuis le fichier temporaire
            if (!faceDetector.load(tempFile.getAbsolutePath())) {
                System.err.println("Erreur lors du chargement du fichier cascade");
            } else {
                System.out.println("Fichier cascade charg√© avec succ√®s.");
            }
        } catch (IOException e) {
            System.err.println("Erreur lors de l'extraction du fichier cascade: " + e.getMessage());
            e.printStackTrace();
        }

        // Cr√©er le r√©pertoire pour les visages s'il n'existe pas
        new File(FACE_DATA_DIR).mkdirs();
    }

    private void initFaceRecognizer() {
        // Initialiser le reconnaisseur de visage avec des param√®tres optimis√©s pour cam√©ras basse qualit√©
        faceRecognizer = LBPHFaceRecognizer.create(
                1,      // radius - rayon pour le voisinage local
                8,      // neighbors - nombre de points d'√©chantillonnage
                8,      // grid_x - nombre de cellules en x
                8,      // grid_y - nombre de cellules en y
                120.0   // threshold - valeur par d√©faut de seuil, augment√©e pour cam√©ras basse qualit√©
        );

        try {
            File modelFile = new File(FACE_DATA_DIR + "face_model.yml");
            if (modelFile.exists()) {
                faceRecognizer.read(modelFile.getAbsolutePath());
                System.out.println("Mod√®le de reconnaissance faciale charg√© depuis: " + modelFile.getAbsolutePath());
            } else {
                // Entra√Æner avec les visages disponibles si le mod√®le n'existe pas
                trainRecognizer();
                System.out.println("Aucun mod√®le existant trouv√©, cr√©ation d'un nouveau mod√®le de reconnaissance");
            }
        } catch (Exception e) {
            System.err.println("Erreur lors du chargement du mod√®le de reconnaissance: " + e.getMessage());
        }
    }

    /**
     * Am√©liore la qualit√© d'une image pour compenser les cam√©ras de faible qualit√©
     * @param image L'image √† am√©liorer
     * @return L'image am√©lior√©e
     */
    private Mat enhanceImage(Mat image) {
        Mat enhanced = new Mat();

        // Am√©liorer la luminosit√© et le contraste
        image.convertTo(enhanced, -1, BRIGHTNESS_ALPHA, BRIGHTNESS_BETA);

        // R√©duire le bruit
        GaussianBlur(enhanced, enhanced, new Size(3, 3), 0);

        return enhanced;
    }

    private void trainRecognizer() {
        List<Mat> faces = new ArrayList<>();
        List<Integer> labels = new ArrayList<>();

        // Parcourir le r√©pertoire des visages stock√©s pour l'entra√Ænement
        File faceDir = new File(FACE_DATA_DIR);
        if (faceDir.exists() && faceDir.isDirectory()) {
            File[] userDirs = faceDir.listFiles();
            if (userDirs != null) {
                for (File userDir : userDirs) {
                    if (userDir.isDirectory()) {
                        try {
                            int userId = Integer.parseInt(userDir.getName());
                            File[] faceFiles = userDir.listFiles();
                            if (faceFiles != null) {
                                for (File faceFile : faceFiles) {
                                    if (faceFile.isFile() && faceFile.getName().endsWith(".jpg")) {
                                        Mat face = imread(faceFile.getAbsolutePath(), IMREAD_GRAYSCALE);
                                        if (!face.empty()) {
                                            // V√©rifier que l'image est de la bonne taille
                                            if (face.rows() != FACE_IMAGE_SIZE || face.cols() != FACE_IMAGE_SIZE) {
                                                resize(face, face, new Size(FACE_IMAGE_SIZE, FACE_IMAGE_SIZE));
                                            }
                                            faces.add(face);
                                            labels.add(userId);
                                            System.out.println("Ajout du visage pour l'utilisateur " + userId + ": " + faceFile.getAbsolutePath());
                                        }
                                    }
                                }
                            }
                        } catch (NumberFormatException e) {
                            // Ignorer les r√©pertoires qui ne sont pas des nombres
                            System.out.println("Ignor√© r√©pertoire non num√©rique: " + userDir.getName());
                        }
                    }
                }
            }
        }

        if (!faces.isEmpty()) {
            System.out.println("Entra√Ænement du mod√®le avec " + faces.size() + " visages");
            MatVector facesMat = new MatVector(faces.size());
            Mat labelsMat = new Mat(labels.size(), 1, CV_32SC1);
            IntPointer labelsPtr = new IntPointer(labelsMat.ptr());

            for (int i = 0; i < faces.size(); i++) {
                facesMat.put(i, faces.get(i));
                labelsPtr.put(i, labels.get(i));
            }

            faceRecognizer.train(facesMat, labelsMat);
            faceRecognizer.save(FACE_DATA_DIR + "face_model.yml");
            System.out.println("Mod√®le entra√Æn√© et sauvegard√© avec succ√®s");
        } else {
            System.out.println("Aucun visage trouv√© pour l'entra√Ænement");
        }
    }

    /**
     * Dessine une interface utilisateur am√©lior√©e sur l'image
     * @param image L'image sur laquelle dessiner l'interface
     * @param message Message principal √† afficher
     * @param progress Message de progression
     * @param isSuccess Indique si une op√©ration a r√©ussi (pour changer la couleur)
     */
    private void drawEnhancedUI(Mat image, String message, String progress, boolean isSuccess) {
        // Dessiner un panneau semi-transparent en haut
        Mat overlay = image.clone();
        rectangle(overlay,
                new Rect(0, 0, image.cols(), 60),
                new Scalar(40, 40, 40, 0.8),
                -1, LINE_8, 0);

        // Fusionner l'overlay avec l'image originale
        addWeighted(overlay, 0.7, image, 0.3, 0, image);

        // Dessiner le titre principal
        putText(image, message,
                new Point(10, 30),
                FONT_HERSHEY_SIMPLEX, 0.9,
                isSuccess ? new Scalar(0, 255, 0, 1) : new Scalar(255, 255, 255, 1),
                2, LINE_AA, false);

        // Dessiner la barre de progression en bas
        rectangle(overlay,
                new Rect(0, image.rows() - 40, image.cols(), 40),
                new Scalar(40, 40, 40, 0.8),
                -1, LINE_8, 0);

        addWeighted(overlay, 0.7, image, 0.3, 0, image);

        putText(image, progress,
                new Point(10, image.rows() - 15),
                FONT_HERSHEY_SIMPLEX, 0.7,
                new Scalar(255, 255, 255, 1),
                1, LINE_AA, false);
    }

    /**
     * Dessine une bordure anim√©e autour d'un rectangle
     * @param image L'image sur laquelle dessiner
     * @param rect Le rectangle √† encadrer
     * @param frame Le num√©ro de frame pour l'animation
     */
    private void drawAnimatedBorder(Mat image, Rect rect, int frame) {
        // Couleurs qui changent en fonction du frame
        double hue = (frame % 100) * 3.6; // 0-360 degr√©s
        Scalar color = new Scalar(0, 0, 0, 1);

        // Animation simple des couleurs: rouge -> jaune -> vert -> cyan -> bleu -> magenta -> rouge
        if (hue < 60) {
            color = new Scalar(0, 255, 255, 1); // cyan
        } else if (hue < 120) {
            color = new Scalar(0, 255, 0, 1); // vert
        } else if (hue < 180) {
            color = new Scalar(255, 255, 0, 1); // jaune
        } else if (hue < 240) {
            color = new Scalar(255, 0, 0, 1); // bleu
        } else if (hue < 300) {
            color = new Scalar(255, 0, 255, 1); // magenta
        } else {
            color = new Scalar(0, 0, 255, 1); // rouge
        }

        // Dessiner le rectangle avec la couleur anim√©e
        rectangle(image, rect, color, 3, LINE_8, 0);

        // Dessiner des guides d'alignement aux coins
        int guideLength = 15;

        // Coin sup√©rieur gauche
        line(image, new Point(rect.x(), rect.y()),
                new Point(rect.x() + guideLength, rect.y()), color, 3, LINE_8, 0);
        line(image, new Point(rect.x(), rect.y()),
                new Point(rect.x(), rect.y() + guideLength), color, 3, LINE_8, 0);

        // Coin sup√©rieur droit
        line(image, new Point(rect.x() + rect.width(), rect.y()),
                new Point(rect.x() + rect.width() - guideLength, rect.y()), color, 3, LINE_8, 0);
        line(image, new Point(rect.x() + rect.width(), rect.y()),
                new Point(rect.x() + rect.width(), rect.y() + guideLength), color, 3, LINE_8, 0);

        // Coin inf√©rieur gauche
        line(image, new Point(rect.x(), rect.y() + rect.height()),
                new Point(rect.x() + guideLength, rect.y() + rect.height()), color, 3, LINE_8, 0);
        line(image, new Point(rect.x(), rect.y() + rect.height()),
                new Point(rect.x(), rect.y() + rect.height() - guideLength), color, 3, LINE_8, 0);

        // Coin inf√©rieur droit
        line(image, new Point(rect.x() + rect.width(), rect.y() + rect.height()),
                new Point(rect.x() + rect.width() - guideLength, rect.y() + rect.height()), color, 3, LINE_8, 0);
        line(image, new Point(rect.x() + rect.width(), rect.y() + rect.height()),
                new Point(rect.x() + rect.width(), rect.y() + rect.height() - guideLength), color, 3, LINE_8, 0);
    }

    /**
     * Enregistre le visage d'un utilisateur avec une interface am√©lior√©e
     * @param user L'utilisateur dont on enregistre le visage
     * @return true si l'enregistrement a r√©ussi, false sinon
     */
    public boolean registerFace(User user) {
        try {
            // Cr√©er le r√©pertoire pour l'utilisateur
            String userDir = FACE_DATA_DIR + user.getId() + "/";
            File userDirFile = new File(userDir);
            userDirFile.mkdirs();

            // Supprimer les anciennes images si l'utilisateur met √† jour son visage
            if (userDirFile.exists() && userDirFile.isDirectory()) {
                File[] oldFiles = userDirFile.listFiles();
                if (oldFiles != null) {
                    for (File file : oldFiles) {
                        if (file.isFile()) {
                            file.delete();
                        }
                    }
                    System.out.println("Images pr√©c√©dentes supprim√©es pour l'utilisateur " + user.getId());
                }
            }

            // Configurer le grabber de cam√©ra
            FrameGrabber grabber = new OpenCVFrameGrabber(0);
            grabber.start();

            // Configurer la fen√™tre d'affichage avec une taille plus grande
            int frameWidth = 800;
            int frameHeight = 600;

            grabber.setImageWidth(frameWidth);
            grabber.setImageHeight(frameHeight);

            CanvasFrame frame = new CanvasFrame("Enregistrement du visage - " + user.getName(),
                    CanvasFrame.getDefaultGamma() / grabber.getGamma());
            frame.setCanvasSize(frameWidth, frameHeight);
            frame.setDefaultCloseOperation(javax.swing.JFrame.DISPOSE_ON_CLOSE);

            OpenCVFrameConverter.ToMat converter = new OpenCVFrameConverter.ToMat();

            int capturedFaces = 0;
            int frameCount = 0;
            final long startTime = System.currentTimeMillis();
            final long timeout = 60000; // 60 secondes maximum pour l'enregistrement

            // Afficher des instructions initiales
            System.out.println("D√©but de l'enregistrement du visage pour " + user.getName());
            System.out.println("PR√âSENTATION: Phase d'enregistrement facial");

            // Capturer plusieurs images du visage pour l'entra√Ænement
            while (frame.isVisible() && capturedFaces < REGISTER_FACE_COUNT &&
                    (System.currentTimeMillis() - startTime) < timeout) {

                Frame capturedFrame = grabber.grab();
                Mat colorImage = converter.convert(capturedFrame);

                // Am√©liorer la qualit√© de l'image
                Mat enhancedImage = enhanceImage(colorImage);

                Mat grayImage = new Mat();
                cvtColor(enhancedImage, grayImage, COLOR_BGR2GRAY);
                equalizeHist(grayImage, grayImage); // Am√©liorer le contraste

                // D√©tecter les visages avec des param√®tres adapt√©s aux cam√©ras basse qualit√©
                RectVector faces = new RectVector();
                faceDetector.detectMultiScale(
                        grayImage,
                        faces,
                        SCALE_FACTOR,    // facteur d'√©chelle r√©duit
                        MIN_NEIGHBORS,   // minNeighbors r√©duit
                        0,               // flags (non utilis√©s)
                        new Size(MIN_FACE_SIZE, MIN_FACE_SIZE), // taille minimale du visage r√©duite
                        new Size(500, 500) // taille maximale du visage
                );

                // Augmenter le compteur de frames pour l'animation
                frameCount++;

                // Construire les messages d'instructions
                String mainMessage = "üë§ Enregistrement facial de " + user.getName();
                String progressMessage = String.format("üì∏ Captures: %d/%d - Positionnez votre visage au centre",
                        capturedFaces, REGISTER_FACE_COUNT);

                // Dessiner l'interface utilisateur am√©lior√©e
                drawEnhancedUI(colorImage, mainMessage, progressMessage, false);

                if (faces.size() > 0) {
                    // Prendre le plus grand visage (probablement le plus proche)
                    Rect bestFace = getBestFace(faces);

                    // Dessiner une bordure anim√©e autour du visage d√©tect√©
                    drawAnimatedBorder(colorImage, bestFace, frameCount);

                    // Si la taille est suffisante et le visage est bien centr√©
                    if (bestFace.width() >= MIN_FACE_SIZE && bestFace.height() >= MIN_FACE_SIZE) {
                        Mat face = new Mat(grayImage, bestFace);
                        resize(face, face, new Size(FACE_IMAGE_SIZE, FACE_IMAGE_SIZE));

                        // Am√©liorer la qualit√© avec une √©galisation d'histogramme
                        equalizeHist(face, face);

                        // V√©rifier le centrage du visage dans l'image pour une meilleure qualit√©
                        int centerX = colorImage.cols() / 2;
                        int centerY = colorImage.rows() / 2;
                        int faceX = bestFace.x() + bestFace.width() / 2;
                        int faceY = bestFace.y() + bestFace.height() / 2;

                        // Distance du centre (normalis√©e)
                        double centerDist = Math.sqrt(
                                Math.pow((faceX - centerX) / (double)colorImage.cols(), 2) +
                                        Math.pow((faceY - centerY) / (double)colorImage.rows(), 2)
                        );

                        // Afficher une indication visuelle du centrage
                        String centeringMsg;
                        Scalar centerColor;

                        if (centerDist < 0.15) {  // Bien centr√©
                            centeringMsg = "‚úÖ Position id√©ale";
                            centerColor = new Scalar(0, 255, 0, 1);

                            // Sauvegarder l'image √† intervalles pour √©viter les doublons
                            if (frameCount % 5 == 0) { // Toutes les 5 frames
                                String filename = userDir + "face_" + capturedFaces + ".jpg";
                                imwrite(filename, face);
                                capturedFaces++;

                                // Message de confirmation pour chaque visage enregistr√©
                                System.out.println("PR√âSENTATION: Visage " + capturedFaces + "/" + REGISTER_FACE_COUNT +
                                        " captur√© pour " + user.getName());

                                // Afficher un message de confirmation sur l'image
                                Mat captureOverlay = colorImage.clone();
                                rectangle(captureOverlay,
                                        new Rect(bestFace.x() - 10, bestFace.y() - 40, 150, 30),
                                        new Scalar(0, 128, 0, 0.7),
                                        -1, LINE_8, 0);

                                addWeighted(captureOverlay, 0.7, colorImage, 0.3, 0, colorImage);

                                putText(colorImage,
                                        "‚úì Capture " + capturedFaces,
                                        new Point(bestFace.x(), bestFace.y() - 20),
                                        FONT_HERSHEY_SIMPLEX, 0.6,
                                        new Scalar(255, 255, 255, 1),
                                        1, LINE_AA, false);

                                // Ajouter une pause pour rendre la capture visible
                                frame.showImage(converter.convert(colorImage));
                                Thread.sleep(500); // Pause plus longue pour voir la confirmation
                            }
                        } else if (centerDist < 0.25) {  // Acceptable mais pas id√©al
                            centeringMsg = "‚ö†Ô∏è Ajustez position";
                            centerColor = new Scalar(0, 255, 255, 1);
                        } else {  // Trop loin du centre
                            centeringMsg = "‚ùå Recentrez visage";
                            centerColor = new Scalar(0, 0, 255, 1);
                        }

                        // Dessinez un indicateur de centrage
                        putText(colorImage,
                                centeringMsg,
                                new Point(bestFace.x(), bestFace.y() + bestFace.height() + 20),
                                FONT_HERSHEY_SIMPLEX, 0.6,
                                centerColor,
                                1, LINE_AA, false);

                        // Ajouter des indicateurs visuels de direction si mal centr√©
                        if (centerDist >= 0.15) {
                            String directionMsg = "";

                            if (faceY < centerY - 50) directionMsg += "‚Üì";
                            else if (faceY > centerY + 50) directionMsg += "‚Üë";

                            if (faceX < centerX - 50) directionMsg += "‚Üí";
                            else if (faceX > centerX + 50) directionMsg += "‚Üê";

                            putText(colorImage,
                                    directionMsg,
                                    new Point(colorImage.cols() / 2 - 20, colorImage.rows() / 2 + 10),
                                    FONT_HERSHEY_SIMPLEX, 1.2,
                                    new Scalar(0, 200, 255, 1),
                                    2, LINE_AA, false);
                        }
                    }
                } else {
                    // Si aucun visage n'est d√©tect√©, afficher un message d'aide
                    putText(colorImage,
                            "‚ùå Aucun visage d√©tect√© - Rapprochez-vous",
                            new Point(colorImage.cols() / 2 - 200, colorImage.rows() / 2),
                            FONT_HERSHEY_SIMPLEX, 0.8,
                            new Scalar(0, 0, 255, 1),
                            2, LINE_AA, false);
                }

                // Afficher l'image avec les informations de progr√®s
                frame.showImage(converter.convert(colorImage));

                // D√©lai plus long pour rendre les √©tapes bien visibles
                Thread.sleep(DETECTION_DELAY);
            }

            // Si l'enregistrement est termin√© avec succ√®s, montrer un r√©sum√©
            if (capturedFaces >= REGISTER_FACE_COUNT) {
                Frame capturedFrame = grabber.grab();
                Mat colorImage = converter.convert(capturedFrame);

                // Message de succ√®s
                String successMsg = "‚úÖ Enregistrement R√©ussi!";
                String detailMsg = capturedFaces + " visages captur√©s pour " + user.getName();

                drawEnhancedUI(colorImage, successMsg, detailMsg, true);

                // Dessiner un grand symbole de succ√®s
                circle(colorImage,
                        new Point(colorImage.cols() / 2, colorImage.rows() / 2),
                        100, new Scalar(0, 255, 0, 1), -1, LINE_8, 0);

                putText(colorImage,
                        "‚úì",
                        new Point(colorImage.cols() / 2 - 30, colorImage.rows() / 2 + 30),
                        FONT_HERSHEY_SIMPLEX, 3.0,
                        new Scalar(255, 255, 255, 1),
                        3, LINE_AA, false);

                frame.showImage(converter.convert(colorImage));
                Thread.sleep(CONFIRMATION_DELAY); // Afficher plus longtemps le message de succ√®s
            }

            grabber.stop();
            frame.dispose();

            // V√©rifier si nous avons captur√© assez de visages
            if (capturedFaces < REGISTER_FACE_COUNT / 2) {
                System.out.println("PR√âSENTATION: Enregistrement annul√© : pas assez d'images captur√©es pour " + user.getName());
                return false;
            }

            // R√©entra√Æner le mod√®le avec les nouvelles images
            System.out.println("PR√âSENTATION: Entra√Ænement du mod√®le de reconnaissance faciale");
            trainRecognizer();

            // Mettre √† jour l'utilisateur pour indiquer qu'il a une identification faciale
            user.setHasFacialRecognition(true);
            userService.updateUser(user);

            // Message final de confirmation
            System.out.println("PR√âSENTATION: Visage enregistr√© avec succ√®s pour " + user.getName() +
                    " (" + capturedFaces + " images captur√©es)");

            return true;
        } catch (Exception e) {
            System.err.println("Erreur lors de l'enregistrement du visage: " + e.getMessage());
            e.printStackTrace();
            return false;
        }
    }

    /**
     * S√©lectionne le meilleur visage dans une liste de rectangles d√©tect√©s
     * @param faces Collection de rectangles repr√©sentant des visages
     * @return Le rectangle du meilleur visage (g√©n√©ralement le plus grand)
     */
    private Rect getBestFace(RectVector faces) {
        Rect bestFace = faces.get(0);
        int maxArea = bestFace.width() * bestFace.height();

        for (int i = 1; i < faces.size(); i++) {
            Rect face = faces.get(i);
            int area = face.width() * face.height();
            if (area > maxArea) {
                maxArea = area;
                bestFace = face;
            }
        }

        return bestFace;
    }

    /**
     * Reconna√Æt un utilisateur par son visage avec une interface am√©lior√©e
     * @return L'utilisateur reconnu ou null si aucun utilisateur n'est reconnu
     * @throws Exception En cas d'erreur lors de la reconnaissance
     */
    public User recognizeFace() throws Exception {
        FrameGrabber grabber = new OpenCVFrameGrabber(0);
        grabber.start();

        // Configurer la fen√™tre d'affichage avec une taille plus grande
        int frameWidth = 800;
        int frameHeight = 600;

        grabber.setImageWidth(frameWidth);
        grabber.setImageHeight(frameHeight);

        CanvasFrame frame = new CanvasFrame("Reconnaissance faciale",
                CanvasFrame.getDefaultGamma() / grabber.getGamma());
        frame.setCanvasSize(frameWidth, frameHeight);
        frame.setDefaultCloseOperation(javax.swing.JFrame.DISPOSE_ON_CLOSE);

        OpenCVFrameConverter.ToMat converter = new OpenCVFrameConverter.ToMat();

        User recognizedUser = null;
        int attempts = 0;
        int frameCount = 0;
        int consecutiveMatches = 0; // Pour une reconnaissance plus stable
        User lastMatchedUser = null;

        System.out.println("PR√âSENTATION: D√©marrage de la reconnaissance faciale...");

        while (frame.isVisible() && attempts < RECOGNITION_ATTEMPTS) {
            Frame capturedFrame = grabber.grab();
            Mat colorImage = converter.convert(capturedFrame);

            // Am√©liorer la qualit√© de l'image
            Mat enhancedImage = enhanceImage(colorImage);

            Mat grayImage = new Mat();
            cvtColor(enhancedImage, grayImage, COLOR_BGR2GRAY);
            equalizeHist(grayImage, grayImage);

            // D√©tecter les visages avec des param√®tres optimis√©s
            RectVector faces = new RectVector();
            faceDetector.detectMultiScale(
                    grayImage,
                    faces,
                    SCALE_FACTOR,    // facteur d'√©chelle
                    MIN_NEIGHBORS,   // minNeighbors - plus √©lev√© pour r√©duire les faux positifs
                    0,               // flags
                    new Size(MIN_FACE_SIZE, MIN_FACE_SIZE), // taille minimale
                    new Size(500, 500)    // taille maximale
            );

            // Augmenter le compteur de frames pour l'animation
            frameCount++;

            // Construire les messages d'interface
            String mainMessage = "üîç Reconnaissance faciale en cours";
            String progressMessage = String.format("Tentative: %d/%d", attempts + 1, RECOGNITION_ATTEMPTS);

            // Dessiner l'interface utilisateur am√©lior√©e
            drawEnhancedUI(colorImage, mainMessage, progressMessage, false);

            if (!faces.empty()) {
                // Prendre le meilleur visage
                Rect bestFace = getBestFace(faces);

                // Dessiner une bordure anim√©e autour du visage
                drawAnimatedBorder(colorImage, bestFace, frameCount);

                // Ignorer les visages trop petits pour une bonne pr√©cision
                if (bestFace.width() >= MIN_FACE_SIZE && bestFace.height() >= MIN_FACE_SIZE) {
                    // Extraire et pr√©traiter le visage pour la reconnaissance
                    Mat faceROI = new Mat(grayImage, bestFace);
                    resize(faceROI, faceROI, new Size(FACE_IMAGE_SIZE, FACE_IMAGE_SIZE));
                    equalizeHist(faceROI, faceROI); // Am√©liorer le contraste

                    // Pr√©dire l'identit√©
                    IntPointer label = new IntPointer(1);
                    DoublePointer confidence = new DoublePointer(1);
                    faceRecognizer.predict(faceROI, label, confidence);

                    int predictedLabel = label.get(0);
                    double conf = confidence.get(0);

                    // Afficher le score de confiance
                    putText(colorImage,
                            String.format("Confiance: %.1f", conf),
                            new Point(bestFace.x(), bestFace.y() - 10),
                            FONT_HERSHEY_SIMPLEX, 0.6, new Scalar(0, 0, 255, 1), 2, LINE_AA, false);

                    // Si la confiance est assez haute (valeur plus basse = plus confiant)
                    if (conf < RECOGNITION_THRESHOLD) {
                        User user = userService.getUserById(predictedLabel);
                        if (user != null) {
                            // V√©rifier si c'est le m√™me utilisateur que la d√©tection pr√©c√©dente
                            if (lastMatchedUser != null && lastMatchedUser.getId() == user.getId()) {
                                consecutiveMatches++;
                            } else {
                                consecutiveMatches = 1;
                                lastMatchedUser = user;
                            }

                            // Afficher le nom de l'utilisateur reconnu
                            putText(colorImage,
                                    user.getName() + (consecutiveMatches > 1 ? " ‚úì" + consecutiveMatches : ""),
                                    new Point(bestFace.x(), bestFace.y() - 30),
                                    FONT_HERSHEY_SIMPLEX, 0.8, new Scalar(0, 255, 0, 1), 2, LINE_AA, false);

                            // Si nous avons 3 d√©tections cons√©cutives du m√™me utilisateur, c'est confirm√©
                            if (consecutiveMatches >= 3) {
                                recognizedUser = user;

                                // Mettre √† jour l'interface pour montrer la confirmation
                                mainMessage = "‚úÖ Utilisateur reconnu!";
                                progressMessage = user.getName();
                                drawEnhancedUI(colorImage, mainMessage, progressMessage, true);

                                // Afficher confirmation visuelle
                                rectangle(colorImage, bestFace, new Scalar(0, 255, 0, 1), 3, LINE_8, 0);

                                // Dessiner un symbole de confirmation
                                circle(colorImage,
                                        new Point(colorImage.cols() / 2, colorImage.rows() / 2),
                                        100, new Scalar(0, 255, 0, 1), -1, LINE_8, 0);

                                putText(colorImage,
                                        "‚úì",
                                        new Point(colorImage.cols() / 2 - 30, colorImage.rows() / 2 + 30),
                                        FONT_HERSHEY_SIMPLEX, 3.0,
                                        new Scalar(255, 255, 255, 1),
                                        3, LINE_AA, false);

                                // Attendre un moment pour que l'utilisateur voie la confirmation
                                frame.showImage(converter.convert(colorImage));
                                Thread.sleep(CONFIRMATION_DELAY);
                                break;
                            }
                        }
                    }
                }
            } else {
                // Afficher un message d'aide si aucun visage n'est d√©tect√©
                putText(colorImage,
                        "‚ùå Aucun visage d√©tect√© - Rapprochez-vous",
                        new Point(colorImage.cols() / 2 - 200, colorImage.rows() / 2),
                        FONT_HERSHEY_SIMPLEX, 0.8,
                        new Scalar(0, 0, 255, 1),
                        2, LINE_AA, false);
            }

            // Afficher l'image avec les rectangles et les noms
            frame.showImage(converter.convert(colorImage));
            attempts++;

            // Petit d√©lai pour r√©duire la charge CPU
            Thread.sleep(DETECTION_DELAY);
        }

        grabber.stop();
        frame.dispose();

        if (recognizedUser != null) {
            System.out.println("PR√âSENTATION: Utilisateur reconnu: " + recognizedUser.getName());
        } else {
            System.out.println("PR√âSENTATION: Aucun utilisateur reconnu apr√®s " + attempts + " tentatives");
        }

        return recognizedUser;
    }

    /**
     * V√©rifie si le visage d√©tect√© correspond √† l'utilisateur sp√©cifi√©
     * @param user L'utilisateur √† v√©rifier
     * @return true si le visage correspond √† l'utilisateur, false sinon
     * @throws Exception En cas d'erreur lors de la v√©rification
     */
    public boolean verifyUserFace(User user) throws Exception {
        if (user == null) {
            System.err.println("Erreur: utilisateur null fourni pour la v√©rification faciale");
            return false;
        }

        FrameGrabber grabber = new OpenCVFrameGrabber(0);
        grabber.start();

        // Configurer la fen√™tre d'affichage avec une taille plus grande
        int frameWidth = 800;
        int frameHeight = 600;

        grabber.setImageWidth(frameWidth);
        grabber.setImageHeight(frameHeight);

        CanvasFrame frame = new CanvasFrame("V√©rification du visage - " + user.getName(),
                CanvasFrame.getDefaultGamma() / grabber.getGamma());
        frame.setCanvasSize(frameWidth, frameHeight);
        frame.setDefaultCloseOperation(javax.swing.JFrame.DISPOSE_ON_CLOSE);

        OpenCVFrameConverter.ToMat converter = new OpenCVFrameConverter.ToMat();

        boolean isVerified = false;
        int attempts = 0;
        int frameCount = 0;
        int consecutiveMatches = 0;
        final int requiredMatches = 3; // Nombre de correspondances cons√©cutives requises

        System.out.println("PR√âSENTATION: D√©marrage de la v√©rification faciale pour " + user.getName());

        while (frame.isVisible() && attempts < RECOGNITION_ATTEMPTS && !isVerified) {
            Frame capturedFrame = grabber.grab();
            Mat colorImage = converter.convert(capturedFrame);

            // Am√©liorer la qualit√© de l'image
            Mat enhancedImage = enhanceImage(colorImage);

            Mat grayImage = new Mat();
            cvtColor(enhancedImage, grayImage, COLOR_BGR2GRAY);
            equalizeHist(grayImage, grayImage);

            // D√©tecter les visages
            RectVector faces = new RectVector();
            faceDetector.detectMultiScale(
                    grayImage,
                    faces,
                    SCALE_FACTOR,  // facteur d'√©chelle
                    MIN_NEIGHBORS,// minNeighbors
                    0,            // flags
                    new Size(MIN_FACE_SIZE, MIN_FACE_SIZE),  // taille minimale
                    new Size(500, 500) // taille maximale
            );

            // Augmenter le compteur de frames pour l'animation
            frameCount++;

            // Construire les messages d'interface
            String mainMessage = "üîç V√©rification de " + user.getName();
            String progressMessage = String.format("Tentative: %d/%d", attempts + 1, RECOGNITION_ATTEMPTS);

            // Dessiner l'interface utilisateur am√©lior√©e
            drawEnhancedUI(colorImage, mainMessage, progressMessage, false);

            if (!faces.empty()) {
                // Prendre le meilleur visage
                Rect bestFace = getBestFace(faces);

                // Dessiner une bordure anim√©e autour du visage
                drawAnimatedBorder(colorImage, bestFace, frameCount);

                // Ignorer les visages trop petits
                if (bestFace.width() >= MIN_FACE_SIZE && bestFace.height() >= MIN_FACE_SIZE) {
                    Mat faceROI = new Mat(grayImage, bestFace);
                    resize(faceROI, faceROI, new Size(FACE_IMAGE_SIZE, FACE_IMAGE_SIZE));
                    equalizeHist(faceROI, faceROI);

                    IntPointer label = new IntPointer(1);
                    DoublePointer confidence = new DoublePointer(1);
                    faceRecognizer.predict(faceROI, label, confidence);

                    int predictedLabel = label.get(0);
                    double conf = confidence.get(0);

                    // Afficher le score de confiance
                    putText(colorImage,
                            String.format("Confiance: %.1f", conf),
                            new Point(bestFace.x(), bestFace.y() - 10),
                            FONT_HERSHEY_SIMPLEX, 0.6, new Scalar(0, 0, 255, 1), 2, LINE_AA, false);

                    // V√©rifier si c'est l'utilisateur attendu avec une bonne confiance
                    if (predictedLabel == user.getId() && conf < VERIFICATION_THRESHOLD) {
                        consecutiveMatches++;

                        // Afficher le nom avec une indicateur de correspondance
                        putText(colorImage,
                                user.getName() + " ‚úì" + consecutiveMatches,
                                new Point(bestFace.x(), bestFace.y() - 30),
                                FONT_HERSHEY_SIMPLEX, 0.8, new Scalar(0, 255, 0, 1), 2, LINE_AA, false);

                        // Rectangle vert si correspondance
                        rectangle(colorImage, bestFace, new Scalar(0, 255, 0, 1), 2, LINE_8, 0);

                        // Si nous avons assez de correspondances cons√©cutives
                        if (consecutiveMatches >= requiredMatches) {
                            isVerified = true;

                            // Mettre √† jour l'interface pour montrer la confirmation
                            mainMessage = "‚úÖ V√©rification r√©ussie!";
                            progressMessage = user.getName();
                            drawEnhancedUI(colorImage, mainMessage, progressMessage, true);

                            // Message de confirmation
                            rectangle(colorImage, bestFace, new Scalar(0, 255, 0, 1), 3, LINE_8, 0);

                            // Dessiner un symbole de confirmation
                            circle(colorImage,
                                    new Point(colorImage.cols() / 2, colorImage.rows() / 2),
                                    100, new Scalar(0, 255, 0, 1), -1, LINE_8, 0);

                            putText(colorImage,
                                    "‚úì",
                                    new Point(colorImage.cols() / 2 - 30, colorImage.rows() / 2 + 30),
                                    FONT_HERSHEY_SIMPLEX, 3.0,
                                    new Scalar(255, 255, 255, 1),
                                    3, LINE_AA, false);
                        }
                    } else {
                        // R√©initialiser le compteur de correspondances en cas d'√©chec
                        consecutiveMatches = 0;
                    }
                }
            } else {
                // Afficher un message d'aide si aucun visage n'est d√©tect√©
                putText(colorImage,
                        "‚ùå Aucun visage d√©tect√© - Rapprochez-vous",
                        new Point(colorImage.cols() / 2 - 200, colorImage.rows() / 2),
                        FONT_HERSHEY_SIMPLEX, 0.8,
                        new Scalar(0, 0, 255, 1),
                        2, LINE_AA, false);
            }

            frame.showImage(converter.convert(colorImage));
            attempts++;

            // Petit d√©lai
            Thread.sleep(DETECTION_DELAY);

            // Si v√©rifi√©, attendre un moment pour afficher le message de confirmation
            if (isVerified) {
                Thread.sleep(CONFIRMATION_DELAY);
            }
        }

        grabber.stop();
        frame.dispose();

        if (isVerified) {
            System.out.println("PR√âSENTATION: Identit√© de " + user.getName() + " v√©rifi√©e avec succ√®s");
        } else {
            System.out.println("PR√âSENTATION: √âchec de la v√©rification pour " + user.getName() + " apr√®s " + attempts + " tentatives");
        }

        return isVerified;
    }
}